{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 16:57:27.091186: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-22 16:57:27.105942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742662647.123364   86994 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742662647.128332   86994 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742662647.141208   86994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742662647.141230   86994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742662647.141232   86994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742662647.141234   86994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-22 16:57:27.145540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, RNN, Dropout, Bidirectional\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.backend as ops\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 120\n",
    "n = 30000  # Set the number of most frequent words to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run enum\n",
    "class ModelRunMode(Enum):\n",
    "    \"\"\"\n",
    "    Enumeration of Model Run Mode.\n",
    "    \"\"\"\n",
    "    TRAIN           = \"train\"           # Train Mode\n",
    "    CLASSIFY        = \"classify\"        # Classify Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run mode\n",
    "# Options: \n",
    "#   ModelRunMode.TRAIN.value            (Train the model)\n",
    "#   ModelRunMode.CLASSIFY.value         (Classify data)\n",
    "mode = ModelRunMode.CLASSIFY.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters cell\n",
    "if mode == ModelRunMode.CLASSIFY.value:\n",
    "    # CLASSIFY mode: Set parameters for classification\n",
    "    input_csv = \"classify_input_datasets/dataset3_inputs.csv\"               # CSV file with texts for prediction (ID, Text)\n",
    "    output_csv = \"classify_output_datasets/dataset3_outputs_lstm_model.csv\"  # CSV file to store prediction result\n",
    "elif mode == ModelRunMode.TRAIN.value:\n",
    "    ...\n",
    "else:\n",
    "    print(\"The selected option is not valid. Options: \\\"train\\\" or \\\"classify\\\"!\")\n",
    "    SystemExit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining global fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stopwords = True):\n",
    "    def normalize(text):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove numbers, special characters, e o caractere '\n",
    "        text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Add start and end sequence tokens\n",
    "        # text = 'startseq ' + \" \".join([word for word in text.split() if len(word) > 1]) + ' endseq'\n",
    "        return text\n",
    "\n",
    "    def remove_stopwords(text):\n",
    "        stopwords = [\n",
    "        \"the\", \"of\", \"and\", \"in\", \"to\", \"is\", \"a\", \"that\", \"for\", \"are\", \"on\", \"with\", \n",
    "        \"as\", \"at\", \"by\", \"from\", \"this\", \"it\", \"an\", \"be\", \"or\", \"which\", \"was\", \"were\"\n",
    "        ]\n",
    "        text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "        return text\n",
    "    \n",
    "    text = normalize(text)\n",
    "    if stopwords:\n",
    "        text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, texts, n_words=None):\n",
    "        self.n_words = n_words\n",
    "        self.texts = texts\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        self.create_index()\n",
    "        \n",
    "\n",
    "    def create_index(self):\n",
    "        word_counter = Counter()\n",
    "        for caption in self.texts:\n",
    "            for word in caption.split():\n",
    "                word_counter[word] += 1\n",
    "\n",
    "        # Sort words by frequency and alphabetically for ties\n",
    "        most_common = word_counter.most_common(self.n_words) if self.n_words else word_counter.items()\n",
    "        self.vocab = [word for word, _ in sorted(most_common, key=lambda x: (-x[1], x[0]))]\n",
    "\n",
    "        # Add special tokens\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        self.word2idx['<unk>'] = 1\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 2\n",
    "\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word\n",
    "\n",
    "\n",
    "    def encode(self, caption):\n",
    "        tokens = []\n",
    "        for word in caption.split():\n",
    "            if word in self.word2idx:\n",
    "                tokens.append(self.word2idx[word])\n",
    "            else:\n",
    "                tokens.append(self.word2idx['<unk>'])\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return ' '.join([self.idx2word.get(token, '<unk>') for token in tokens])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, tokenizer,max_length=120):\n",
    "\n",
    "    X = df['Text']\n",
    "    # y = df['Label'].apply(lambda x: 0 if x == 0 else 1)\n",
    "    y = df['Label']\n",
    "    X = X.apply(lambda x: tokenizer.encode(x))\n",
    "    X = pad_sequences(X, maxlen=max_length, padding='pre')\n",
    "    # y = to_categorical(y)[:,1]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper we enumerate prime graphs respect cartes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research paper investigates resummed cross sec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red supergiant stars represent key phase evolu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we investigate effects all orders planck lengt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we introduce novel extension gutzwiller variat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>effect li substitution mg lic cosubstitution s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>research paper titled energy efficiency perspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>research paper presents results optical spectr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>using molecular simulations we show aperiodic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>abstract quantum chromodynamics qcd fundamenta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4053 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     paper we enumerate prime graphs respect cartes...      0\n",
       "1     research paper investigates resummed cross sec...      1\n",
       "2     red supergiant stars represent key phase evolu...      0\n",
       "3     we investigate effects all orders planck lengt...      0\n",
       "4     we introduce novel extension gutzwiller variat...      0\n",
       "...                                                 ...    ...\n",
       "4048  effect li substitution mg lic cosubstitution s...      0\n",
       "4049  research paper titled energy efficiency perspe...      1\n",
       "4050  research paper presents results optical spectr...      1\n",
       "4051  using molecular simulations we show aperiodic ...      0\n",
       "4052  abstract quantum chromodynamics qcd fundamenta...      1\n",
       "\n",
       "[4053 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('../tarefa_1/clean_input_datasets/gpt_vs_human_data_set_inputs.csv',sep='\\t', index_col=False)['Text']\n",
    "y = pd.read_csv('../tarefa_1/clean_output_datasets/gpt_vs_human_data_set_outputs.csv',sep='\\t', index_col=False)['Label']\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "df['Text'] = df['Text'].str.replace('\\n', ' ')\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Label'] = df['Label'].apply(lambda x: 1 if x == \"AI\" else 0)\n",
    "df['Text'] = df['Text'].apply(clean)\n",
    "#shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cell cycle celldivision cycle sequential serie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell cycle process cell grows duplicates its d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>photons many atomic models physics particles t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>photon fundamental particle light other electr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according theory plate tectonics earths lithos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>research paper explores concept topological in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>we report experimental realization oneway quan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>research paper presents experimental realizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>airwater interface alkylbiphenylcarbonitrile c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>research paper investigates line tension struc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label\n",
       "0   cell cycle celldivision cycle sequential serie...      0\n",
       "1   cell cycle process cell grows duplicates its d...      1\n",
       "2   photons many atomic models physics particles t...      0\n",
       "3   photon fundamental particle light other electr...      1\n",
       "4   according theory plate tectonics earths lithos...      0\n",
       "..                                                ...    ...\n",
       "95  research paper explores concept topological in...      1\n",
       "96  we report experimental realization oneway quan...      0\n",
       "97  research paper presents experimental realizati...      1\n",
       "98  airwater interface alkylbiphenylcarbonitrile c...      0\n",
       "99  research paper investigates line tension struc...      1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_1 = pd.read_csv('../tarefa_1/clean_input_datasets/dataset1_enh_inputs.csv',sep='\\t', index_col=False)['Text']\n",
    "y_val_1 = pd.read_csv('../tarefa_1/clean_output_datasets/dataset1_enh_outputs.csv',sep='\\t', index_col=False)['Label']\n",
    "df_val_1 = pd.concat([X_val_1, y_val_1], axis=1)\n",
    "df_val_1['Text'] = df_val_1['Text'].str.replace('\\n', ' ')\n",
    "df_val_1['Text'] = df_val_1['Text'].astype(str)\n",
    "df_val_1['Label'] = df_val_1['Label'].apply(lambda x: 1 if x == \"AI\" else 0)\n",
    "df_val_1['Text'] = df_val_1['Text'].apply(clean)\n",
    "df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approximation useful chemistry but not strictl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these nutrients needed keep bones teeth muscle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vitamin d essential maintaining healthy bones ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>within million years pressure density hydrogen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there estimated trillion galaxies known univer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>research paper explores concept topological in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>we report experimental realization oneway quan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>research paper presents experimental realizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>airwater interface alkylbiphenylcarbonitrile c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>research paper investigates line tension struc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Label\n",
       "0    approximation useful chemistry but not strictl...      0\n",
       "1    these nutrients needed keep bones teeth muscle...      0\n",
       "2    vitamin d essential maintaining healthy bones ...      1\n",
       "3    within million years pressure density hydrogen...      0\n",
       "4    there estimated trillion galaxies known univer...      0\n",
       "..                                                 ...    ...\n",
       "145  research paper explores concept topological in...      1\n",
       "146  we report experimental realization oneway quan...      0\n",
       "147  research paper presents experimental realizati...      1\n",
       "148  airwater interface alkylbiphenylcarbonitrile c...      0\n",
       "149  research paper investigates line tension struc...      1\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('dataset2_disclosed.csv', sep=';')\n",
    "val_df['Text'] = val_df['Text'].str.replace('\\n', ' ')\n",
    "val_df['Text'] = val_df['Text'].astype(str)\n",
    "val_df['Label'] = val_df['Label'].apply(lambda x: 1 if x == \"AI\" else 0)\n",
    "val_df['Text'] = val_df['Text'].apply(clean)\n",
    "val_df = val_df[['Text', 'Label']]\n",
    "val_df = pd.concat([val_df, df_val_1], axis=0).reset_index(drop=True)\n",
    "val_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the vocabulary: 19081\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(df['Text'], n)\n",
    "vocab_size = len(tokenizer)\n",
    "print('Number of words in the vocabulary:', len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(df, tokenizer, max_length)\n",
    "X_val, y_val = prepare_data(val_df, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     5     3    64   355  1801    48  3266  1085   795  2334  7598   914\n",
      "    18   146  6353   168 18248    46    78   355  1801   258   873  1085\n",
      "   795   752    10   141   914  2334  3193   176   180    65 11532  3980\n",
      "   219  2390  3266    55    46   413   355  1801   729   252   100    58\n",
      "   244  2334    10    33    41   797    20    24  1085   795    19  1748]\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> research paper investigates line tension structure smectic liquid crystal multilayers airwater interface using xray reflectivity surface tensiometry authors found line tension related thickness liquid crystal layers their interactions interface multilayers exhibited range structures including wellordered hexagonal lattice disordered smectic phase authors conclude line tension plays crucial role formation stability multilayers their findings provide insight into behavior liquid crystal systems interfaces\n"
     ]
    }
   ],
   "source": [
    "print(X_val[-1])\n",
    "print(tokenizer.decode(X_val[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def hyperparameter_optimization_lstm(train_ds, validation_ds, \n",
    "                                     epochs_list, batch_size_list, \n",
    "                                     learning_rate_list, lstm_units_list,\n",
    "                                     embed_dim_list, \n",
    "                                     dropout_list, n_iter=10):\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    best_acc = 0.0\n",
    "    best_params = {}\n",
    "\n",
    "    # Prepare random combinations\n",
    "    param_combinations = []\n",
    "    for _ in range(n_iter):\n",
    "        param_combinations.append({\n",
    "            'epochs': random.choice(epochs_list),\n",
    "            'batch_size': random.choice(batch_size_list),\n",
    "            'learning_rate': random.choice(learning_rate_list),\n",
    "            'lstm_units': random.choice(lstm_units_list),\n",
    "            'dropout_rate': random.choice(dropout_list),\n",
    "            'embed_dim': random.choice(embed_dim_list)\n",
    "        })\n",
    "\n",
    "    # Extract input shape and number of classes\n",
    "    input_shape = train_ds.element_spec[0].shape\n",
    "    print(\"Input Shape:\", input_shape)\n",
    "\n",
    "    for i,params in enumerate(param_combinations):\n",
    "        print(f\"\\nIteration {i+1}/{n_iter}\", end=' ')\n",
    "        # Unpack parameters\n",
    "        epochs = params['epochs']\n",
    "        batch_size = params['batch_size']\n",
    "        learning_rate = params['learning_rate']\n",
    "        lstm_units = params['lstm_units']\n",
    "        dropout_rate = params['dropout_rate']\n",
    "        embed_dim = params['embed_dim']\n",
    "\n",
    "        # Build LSTM model\n",
    "        inputs = keras.Input(shape=(input_shape[1],))  # Assuming (timesteps, features)\n",
    "\n",
    "        x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "\n",
    "        for units in lstm_units[:-1]:\n",
    "            x = layers.Bidirectional(layers.LSTM(units, return_sequences=True))(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "        x = layers.Bidirectional(layers.LSTM(lstm_units[-1]))(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_ds, epochs=epochs, batch_size=batch_size,\n",
    "                            verbose=0, validation_data=validation_ds, callbacks=callbacks)\n",
    "\n",
    "        # Get validation accuracy\n",
    "        val_acc = max(history.history.get('val_accuracy', [0]))\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\", end=' ')\n",
    "        print(f\"Train Accuracy: {max(history.history.get('accuracy', [0])):.4f}\")\n",
    "\n",
    "        # Update best model if improved\n",
    "        if val_acc > best_acc:\n",
    "            best_model = model\n",
    "            best_acc = val_acc\n",
    "            best_params = params\n",
    "\n",
    "    print(\"\\nBest Hyperparameters Found:\", best_params)\n",
    "    print(f\"Best Accuracy: {best_acc:.4f}\")\n",
    "    return best_params, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (None, 120)\n",
      "\n",
      "Iteration 1/10 Validation Accuracy: 0.7867 Train Accuracy: 0.9931\n",
      "\n",
      "Iteration 2/10 Validation Accuracy: 0.7333 Train Accuracy: 0.9998\n",
      "\n",
      "Iteration 3/10 Validation Accuracy: 0.7333 Train Accuracy: 1.0000\n",
      "\n",
      "Iteration 4/10 Validation Accuracy: 0.7467 Train Accuracy: 1.0000\n",
      "\n",
      "Iteration 5/10 Validation Accuracy: 0.7333 Train Accuracy: 1.0000\n",
      "\n",
      "Iteration 6/10 Validation Accuracy: 0.7667 Train Accuracy: 0.9958\n",
      "\n",
      "Iteration 7/10 Validation Accuracy: 0.7867 Train Accuracy: 0.9998\n",
      "\n",
      "Iteration 8/10 Validation Accuracy: 0.7800 Train Accuracy: 0.9998\n",
      "\n",
      "Iteration 9/10 Validation Accuracy: 0.7733 Train Accuracy: 1.0000\n",
      "\n",
      "Iteration 10/10 Validation Accuracy: 0.8133 Train Accuracy: 0.9995\n",
      "\n",
      "Best Hyperparameters Found: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.001, 'lstm_units': [256, 256], 'dropout_rate': 0.7, 'embed_dim': 50}\n",
      "Best Accuracy: 0.8133\n"
     ]
    }
   ],
   "source": [
    "if mode == ModelRunMode.TRAIN.value:\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)\n",
    "\n",
    "    # Hyperparameter search\n",
    "    epochs_list = [10, 20, 30]\n",
    "    batch_size_list = [64]\n",
    "    learning_rate_list = [1e-2, 1e-3, 1e-4]\n",
    "    lstm_units_list = [[64, 64], [128, 128], [256, 256]]\n",
    "    embed_dim_list = [50, 10, 150]\n",
    "    dropout_list = [0.3, 0.5, 0.7]\n",
    "    hiperparams, model = hyperparameter_optimization_lstm(train_ds, val_ds,\n",
    "                                                        epochs_list, batch_size_list,\n",
    "                                                        learning_rate_list, lstm_units_list,\n",
    "                                                        embed_dim_list, dropout_list, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">954,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">628,736</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m954,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m628,736\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,670,475</span> (36.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,670,475\u001b[0m (36.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,223,491</span> (12.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,223,491\u001b[0m (12.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,446,984</span> (24.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,446,984\u001b[0m (24.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if mode == ModelRunMode.TRAIN.value:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "if mode == ModelRunMode.TRAIN.value:\n",
    "    model.save('lstm_model_weights/best_lstm_model.h5')\n",
    "    # save params and tokenizer\n",
    "    import pickle\n",
    "    with open('lstm_model_weights/best_lstm_model_params.pkl', 'wb') as f:\n",
    "        pickle.dump(hiperparams, f)\n",
    "\n",
    "    with open('lstm_model_weights/tokenizer_lstm.pkl', 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFY MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_test(X, tokenizer,max_length=120):\n",
    "    X = X.apply(lambda x: tokenizer.encode(x))\n",
    "    X = pad_sequences(X, maxlen=max_length, padding='pre')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if mode == ModelRunMode.CLASSIFY.value:\n",
    "    X_test = pd.read_csv(input_csv,sep=';', index_col=False)['Text']\n",
    "    ids = pd.read_csv(input_csv,sep=';', index_col=False)['ID']\n",
    "    X_test = X_test.str.replace('\\n', ' ')\n",
    "    X_test = X_test.astype(str)\n",
    "    X_test = X_test.apply(clean)\n",
    "    print(\"CSV loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if mode == ModelRunMode.CLASSIFY.value:\n",
    "    import pickle\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    # open best params and tokenizer\n",
    "    with open('lstm_model_weights/best_lstm_model_params.pkl', 'rb') as f:\n",
    "        hiperparams = pickle.load(f)\n",
    "\n",
    "    with open('lstm_model_weights/tokenizer_lstm.pkl', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "\n",
    "    # print(hiperparams)\n",
    "    # print(tokenizer)\n",
    "\n",
    "    max_length = 120\n",
    "    input_shape = (max_length,)\n",
    "    vocab_size = len(tokenizer)\n",
    "    epochs = hiperparams['epochs']\n",
    "    batch_size = hiperparams['batch_size']\n",
    "    learning_rate = hiperparams['learning_rate']\n",
    "    lstm_units = hiperparams['lstm_units']\n",
    "    dropout_rate = hiperparams['dropout_rate']\n",
    "    embed_dim = hiperparams['embed_dim']\n",
    "\n",
    "    # Build LSTM model\n",
    "    inputs = keras.Input(shape=input_shape)  # Assuming (timesteps, features)\n",
    "\n",
    "    x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "\n",
    "    for units in lstm_units[:-1]:\n",
    "        x = layers.Bidirectional(layers.LSTM(units, return_sequences=True))(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units[-1]))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.load_weights('lstm_model_weights/best_lstm_model.h5')\n",
    "    # print(model.summary())\n",
    "    print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (100, 120)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step\n",
      "(array([0, 1]), array([66, 34]))\n",
      "Prediction saved successfully\n"
     ]
    }
   ],
   "source": [
    "if mode == ModelRunMode.CLASSIFY.value:\n",
    "    X_test = prepare_data_test(X_test, tokenizer, max_length)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    preds = model.predict(X_test)\n",
    "    preds = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "    print(np.unique(preds, return_counts=True))\n",
    "    preds_str = ['AI' if pred == 1 else 'Human' for pred in preds]\n",
    "    result = pd.DataFrame({'ID': ids, 'Label': preds_str})\n",
    "    result.to_csv(output_csv, index=False, sep='\\t')\n",
    "    print(\"Prediction saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
