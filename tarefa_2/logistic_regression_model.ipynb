{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e117c95a",
      "metadata": {},
      "source": [
        "# Logistic Regression Model Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7f3362",
      "metadata": {},
      "source": [
        "```md\n",
        "@author: miguelrocha\n",
        "(Adapted by: Grupo 03)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00553163",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Notebook Imports\n",
        "import numpy as np\n",
        "\n",
        "from models.logistic_regression_model import LogisticRegression, hyperparameter_tuning\n",
        "from helpers.dataset import Dataset\n",
        "from helpers.model import save_model\n",
        "from helpers.metrics import confusion_matrix, balanced_accuracy, precision_recall_f1\n",
        "from helpers.enums import ModelRunMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6f6268",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model run mode\n",
        "# Options: \n",
        "#   ModelRunMode.TRAIN.value            (Train the model)\n",
        "#   ModelRunMode.CLASSIFY.value         (Classify data)\n",
        "mode = ModelRunMode.TRAIN.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fdaeeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters cell\n",
        "if mode == ModelRunMode.TRAIN.value:\n",
        "    # Train mode\n",
        "    input_csv = \"../tarefa_1/clean_input_datasets/ai_human_input_sm.csv\"              # CSV for training input (ID, Text)\n",
        "    output_csv = \"../tarefa_1/clean_output_datasets/ai_human_output_sm.csv\"           # CSV for training output (ID, Label)\n",
        "    model_prefix = \"logreg_model\"                                                   # Prefix for saving the model files\n",
        "    test_size = 0.3                                                                 # Proportion of the dataset to use as test data\n",
        "    regularization = True                                                           # Use L2 regularization approach\n",
        "    lamda = 0.5                                                                     # Lambda for L2 regularization\n",
        "    alpha = 0.001                                                                   # Learning rate for gradient descent\n",
        "    iters = 40000                                                                   # Iterations for gradient descent\n",
        "elif mode == ModelRunMode.CLASSIFY.value:\n",
        "    # Classify mode\n",
        "    input_csv = \"../tarefa_1/clean_input_datasets/dataset1_inputs.csv\"              # CSV for training input (ID, Text)\n",
        "    output_csv = \"../tarefa_1/classify_output_datasets/dataset1_outputs.csv\"        # CSV for predictions output\n",
        "    model_prefix = \"logreg_model\"                                                   # Prefix for loading the model files\n",
        "else:\n",
        "    print(\"The selected option is not valid. Options: \\\"train\\\" or \\\"classify\\\"!\")\n",
        "    SystemExit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de2fdb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "if mode == ModelRunMode.TRAIN.value:\n",
        "    # Load Datasets\n",
        "    X_train, y_train, X_test, y_test, vocab, idf = Dataset.prepare_train_test_bow(input_csv=input_csv, output_csv=output_csv, test_size=test_size, max_vocab_size=None, min_freq=4)\n",
        "\n",
        "    # Create Dataset objects for training and testing\n",
        "    train_ds_full = Dataset(X=X_train, Y=y_train)\n",
        "    test_ds = Dataset(X=X_test, Y=y_test)\n",
        "\n",
        "    # Validate Train and Test dataset division\n",
        "    print(f\"Train set has {train_ds_full.nrows()} rows and {train_ds_full.ncols()} columns\")\n",
        "    print(f\"Test set has {test_ds.nrows()} rows and {test_ds.ncols()} columns\\n\")\n",
        "\n",
        "    # Split the full training data into training and validation sets\n",
        "    n_train = train_ds_full.X.shape[0]\n",
        "    indices = np.arange(n_train)\n",
        "    np.random.shuffle(indices)\n",
        "    split_idx = int(0.7 * n_train)\n",
        "    train_idx = indices[:split_idx]\n",
        "    val_idx = indices[split_idx:]\n",
        "    train_ds = Dataset(X=train_ds_full.X[train_idx], Y=train_ds_full.Y[train_idx])\n",
        "    val_ds = Dataset(X=train_ds_full.X[val_idx], Y=train_ds_full.Y[val_idx])\n",
        "\n",
        "    # Define hyperparameter grids\n",
        "    alphas = [0.001]\n",
        "    lambdas = [0]\n",
        "    iters_list = [20000]\n",
        "\n",
        "    print(\"Starting hyperparameter tuning...\")\n",
        "    best_params, best_acc, results = hyperparameter_tuning(train_ds, val_ds, alphas, lambdas, iters_list)\n",
        "    print(\"\\nBest hyperparameters:\", best_params)\n",
        "    print(\"Best validation accuracy:\", best_acc)\n",
        "\n",
        "    # Retrain model on full training data with best hyperparameters\n",
        "    final_model = LogisticRegression(train_ds_full, regularization=(best_params[\"lamda\"] > 0), lamda=best_params[\"lamda\"])\n",
        "    final_model.gradientDescent(alpha=best_params[\"alpha\"], iters=best_params[\"iters\"])\n",
        "\n",
        "    # Save the model\n",
        "    save_model(final_model.theta, vocab, idf, model_prefix)\n",
        "    print(f\"Model saved with prefix {model_prefix}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    ones_test = np.ones((test_ds.X.shape[0], 1))\n",
        "    X_test_bias = np.hstack((ones_test, test_ds.X))\n",
        "    test_acc = final_model.accuracy(X_test_bias, test_ds.Y)\n",
        "    print(f\"\\nTest accuracy with best hyperparameters: {test_acc:.4f}\")\n",
        "\n",
        "    preds = final_model.predictMany(X_test_bias)\n",
        "    TP, FP, TN, FN = confusion_matrix(y_test, preds)\n",
        "    prec, rec, f1 = precision_recall_f1(y_test, preds)\n",
        "    bal_acc = balanced_accuracy(y_test, preds)\n",
        "\n",
        "    print(\"Confusion Matrix: TP={}, FP={}, TN={}, FN={}\".format(TP, FP, TN, FN))\n",
        "    print(\"Precision = {:.4f}, Recall = {:.4f}, F1 = {:.4f}\".format(prec, rec, f1))\n",
        "    print(\"Balanced Accuracy = {:.4f}\".format(bal_acc))\n",
        "    final_model.plotModel()\n",
        "\n",
        "if mode == ModelRunMode.CLASSIFY.value:\n",
        "    Dataset.classify_texts(input_csv, output_csv, model_prefix=model_prefix)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
