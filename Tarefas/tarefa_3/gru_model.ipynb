{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e117c95a",
      "metadata": {},
      "source": [
        "# Gated Recurrent Units (GRU) Model Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f7f3362",
      "metadata": {},
      "source": [
        "```md\n",
        "@authors: Grupo 03\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00553163",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Notebook Imports\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import re\n",
        "import json\n",
        "import itertools\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, preprocessing, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cee9d6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model run enum\n",
        "class ModelRunMode(Enum):\n",
        "    \"\"\"\n",
        "    Enumeration of Model Run Mode.\n",
        "    \"\"\"\n",
        "    TRAIN           = \"train\"           # Train Mode\n",
        "    CLASSIFY        = \"classify\"        # Classify Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6f6268",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model run mode\n",
        "# Options: \n",
        "#   ModelRunMode.TRAIN.value            (Train the model)\n",
        "#   ModelRunMode.CLASSIFY.value         (Classify data)\n",
        "mode = ModelRunMode.TRAIN.value\n",
        "# Prefix for saving the model files\n",
        "model_prefix = \"gru_model_1\"\n",
        "file_path = \"gru_model_weights\"\n",
        "separator_char = \"\\t\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6adb728",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters cell\n",
        "if mode == ModelRunMode.TRAIN.value:\n",
        "    # TRAIN mode: Set parameters for training\n",
        "    input_csv = \"../tarefa_1/clean_input_datasets/gpt_vs_human_data_set_inputs.csv\"     # CSV file with training inputs (ID, Text)\n",
        "    output_csv = \"../tarefa_1/clean_output_datasets/gpt_vs_human_data_set_outputs.csv\"  # CSV file with training outputs (ID, Label)\n",
        "    test_size = 0.3                                                                     # Proportion of the dataset to use as test data\n",
        "    validation_size = 0.2                                                               # Proportion of the dataset reserved as validation data\n",
        "    random_state=42                                                                     # Seed for reproducible dataset splitting\n",
        "    verbose = True                                                                      # Verbosity level enabler\n",
        "    vocab_size = 1000                                                                   # Max vocabulary size\n",
        "elif mode == ModelRunMode.CLASSIFY.value:\n",
        "    # CLASSIFY mode: Set parameters for classification\n",
        "    input_csv = \"../tarefa_3/classify_input_datasets/dataset3_inputs.csv\"               # CSV file with texts for prediction (ID, Text)\n",
        "    output_csv = \"../tarefa_3/classify_output_datasets/dataset3_outputs_gru_model.csv\"  # CSV file to store prediction result\n",
        "else:\n",
        "    print(\"The selected option is not valid. Options: \\\"train\\\" or \\\"classify\\\"!\")\n",
        "    SystemExit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7713c68b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method to load and merge two datasets by ID column\n",
        "def merge_data_by_id(input_csv, output_csv, sep=\"\\t\"):\n",
        "    df_in = pd.read_csv(input_csv, sep=sep)\n",
        "    df_out = pd.read_csv(output_csv, sep=sep)\n",
        "\n",
        "    # Remove duplicates or NaNs if needed\n",
        "    df_in.dropna(subset=[\"ID\", \"Text\"], inplace=True)\n",
        "    df_out.dropna(subset=[\"ID\", \"Label\"], inplace=True)\n",
        "    df_in.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
        "    df_out.drop_duplicates(subset=[\"ID\"], inplace=True)\n",
        "\n",
        "    df_merged = pd.merge(df_in, df_out, on=\"ID\", how=\"inner\")\n",
        "    return df_merged\n",
        "\n",
        "# Method for text cleaning\n",
        "def text_cleaning(text):\n",
        "        # Download required NLTK resources\n",
        "        nltk.download('stopwords', quiet=True)\n",
        "        nltk.download('punkt_tab', quiet=True)\n",
        "        nltk.download('wordnet', quiet=True)\n",
        "        # Convert text to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http[s]?://\\S+', \"\", text)\n",
        "        # Remove HTML tags\n",
        "        text = re.sub(r\"<[^>]*>\", \"\", text)\n",
        "        # Remove common LaTeX commands\n",
        "        text = re.sub(r\"\\\\[a-zA-Z]+(\\{.*?\\})?\", \"\", text)\n",
        "        # Remove email addresses\n",
        "        text = re.sub(r'\\S+@\\S+', \"\", text)\n",
        "        # Remove punctuation\n",
        "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "        # Remove digits\n",
        "        text = re.sub(r\"\\d+\", \"\", text)\n",
        "        # Replace newlines and extra whitespace with a single space\n",
        "        text = re.sub(r\"\\s+\", \" \", text).replace('\\n', \" \")\n",
        "        # Trim leading and trailing whitespace\n",
        "        text = text.strip()\n",
        "        # Tokenize text and remove stopwords using NLTK's English stopwords list\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # Tokenize text\n",
        "        tokens = word_tokenize(text)\n",
        "        # Remove stopwords\n",
        "        filtered_tokens = [tok for tok in tokens if tok not in stop_words]\n",
        "        # Lemmatize tokens\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        lemmatized_tokens = [lemmatizer.lemmatize(tok) for tok in filtered_tokens]\n",
        "        # Return the cleaned text as a string\n",
        "        return \" \".join(lemmatized_tokens)\n",
        "\n",
        "# Method to convert labels to binary\n",
        "def convert_labels_to_binary_and_get_text(df_merged):\n",
        "    df_merged[\"Label\"] = df_merged[\"Label\"].str.lower().str.strip()\n",
        "    y = np.where(df_merged[\"Label\"] == \"ai\", 1.0, 0.0)\n",
        "    texts = df_merged[\"Text\"].tolist()\n",
        "    return y, texts\n",
        "\n",
        "# Method to plot the learning curves\n",
        "def plot_learning_curves(history):\n",
        "    # Loss\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    if 'val_loss' in history.history:\n",
        "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    \n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    if 'val_accuracy' in history.history:\n",
        "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Method to check label distribution\n",
        "def check_label_distribution(df_merged):\n",
        "    label_counts = df_merged[\"Label\"].value_counts(dropna=False)\n",
        "    print(\"Label distribution:\\n\", label_counts)\n",
        "\n",
        "# Method to print the first 5 cleaned texts\n",
        "def debug_text_cleaning(df_merged):\n",
        "    for i in range(min(5, len(df_merged))):\n",
        "        print(df_merged[\"Text\"].iloc[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f21a18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method to create a GRU-Based classification model\n",
        "def build_gru_model(vocab_size: int, max_len: int, embedding_dim=128, gru_units=64, num_layers=1, dropout_rate=0.0, learning_rate=1e-3, l2_reg=1e-4):\n",
        "    \"\"\"\n",
        "    Create a GRU-based classification model with given hyperparameters.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # Embedding layer\n",
        "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
        "\n",
        "    # Stack GRU Layers and apply dropout to GRU's internal state\n",
        "    for i in range(num_layers):\n",
        "        # For stacked GRUs, the first N-1 GRUs typically return sequences\n",
        "        return_seq = (i < num_layers - 1)\n",
        "        model.add(layers.Bidirectional(layers.GRU(gru_units, return_sequences=return_seq, dropout=dropout_rate, kernel_regularizer=regularizers.l2(l2_reg))))\n",
        "    \n",
        "    # Final Dense layer for classification\n",
        "    model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(l2_reg)))\n",
        "    \n",
        "    # Compile model\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Print model\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43fa4fd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method to tune GRU model hyperparameters\n",
        "def tune_gru_hyperparams(X_train, y_train, X_val, y_val, vocab_size, max_len, param_grid, early_stop_patience=3, reduce_lr_on_plateau_patience=2, reduce_lr_on_plateau_factor=0.5, verbose=1):\n",
        "    best_acc = 0.0\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # Early stopping and reduce learning rate callbacks\n",
        "    callback_list = [\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop_patience, restore_best_weights=True),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=reduce_lr_on_plateau_factor, patience=reduce_lr_on_plateau_patience, verbose=verbose)\n",
        "    ]\n",
        "    \n",
        "    # Generate all combinations of hyperparams from the dictionary\n",
        "    keys = list(param_grid.keys())\n",
        "    all_combinations = list(itertools.product(*(param_grid[k] for k in keys)))\n",
        "    \n",
        "    for combination in all_combinations:\n",
        "        # Build a dictionary with the current params\n",
        "        current_params = dict(zip(keys, combination))\n",
        "        \n",
        "        # Build model\n",
        "        model = build_gru_model(vocab_size=vocab_size, max_len=max_len, embedding_dim=current_params['embedding_dim'], gru_units=current_params['gru_units'], num_layers=current_params['num_layers'], dropout_rate=current_params['dropout_rate'], learning_rate=current_params['learning_rate'])\n",
        "        \n",
        "        # Train model\n",
        "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=current_params['epochs'], batch_size=current_params['batch_size'], callbacks=callback_list, verbose=verbose)\n",
        "        \n",
        "        # Evaluate final val accuracy\n",
        "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=verbose)\n",
        "        \n",
        "        print(\"Params:\", current_params, \"| Val Acc = {:.4f}\".format(val_acc))\n",
        "        \n",
        "        # Keep track of best accuracy (if two combinations yield the same accuracy, we pick the one with the lower validation loss)\n",
        "        if (val_acc > best_acc) or (val_acc == best_acc and val_loss < best_loss):\n",
        "            best_acc = val_acc\n",
        "            best_loss = val_loss\n",
        "            best_params = current_params\n",
        "            best_model = model\n",
        "    \n",
        "    print(\"Best val acc = {:.4f}\".format(best_acc))\n",
        "    print(\"Best hyperparams:\", best_params)\n",
        "    return best_model, best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e633c6f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "if mode == ModelRunMode.TRAIN.value:\n",
        "    # Check if Tensorflow is listing available GPUs (if not, continue with CPU)\n",
        "    print(\"Tensorflow List of GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "    # Load data\n",
        "    df_merged = merge_data_by_id(input_csv, output_csv, sep=separator_char)\n",
        "\n",
        "    # Check label distribution\n",
        "    check_label_distribution(df_merged=df_merged)\n",
        "\n",
        "    # Text cleaning\n",
        "    df_merged[\"Text\"] = df_merged[\"Text\"].apply(text_cleaning)\n",
        "\n",
        "    # Print the first 5 cleaned texts\n",
        "    debug_text_cleaning(df_merged)\n",
        "\n",
        "    # Convert Label: \"AI\" -> 1, \"Human\" -> 0\n",
        "    y, texts = convert_labels_to_binary_and_get_text(df_merged)\n",
        "\n",
        "    # Creating tokenizer\n",
        "    tokenizer = preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "\n",
        "    # Convert to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Calculate 90th percentile sequence length and pad sequences accordingly\n",
        "    lengths = [len(seq) for seq in sequences]\n",
        "    max_len = int(np.percentile(lengths, 90))\n",
        "\n",
        "    # Pad sequences\n",
        "    X = preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Split entire dataset into train_val vs test\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state,stratify=y)\n",
        "\n",
        "    # Split train_val into train vs val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=validation_size, random_state=random_state, stratify=y_train_val)\n",
        "\n",
        "    # Hyperparameter Tuning\n",
        "    param_grid = {\n",
        "        'embedding_dim': [32, 64],\n",
        "        'gru_units': [32, 64],\n",
        "        'num_layers': [1],\n",
        "        'learning_rate': [1e-3, 1e-2],\n",
        "        'dropout_rate': [0.01, 0.1],\n",
        "        'epochs': [5, 10],\n",
        "        'batch_size': [16, 32]\n",
        "    }\n",
        "\n",
        "    # Finetune GRU Hyperparameters\n",
        "    best_model, best_params = tune_gru_hyperparams(X_train, y_train, X_val, y_val, vocab_size=vocab_size, max_len=max_len, param_grid=param_grid)\n",
        "\n",
        "    # Display model sumary\n",
        "    best_model.summary()\n",
        "\n",
        "    # Evaluate best_model on the validation set\n",
        "    val_loss, val_acc = best_model.evaluate(X_val, y_val, verbose=1)\n",
        "    print(f\"Validation Accuracy (best model): {val_acc:.4f}\")\n",
        "\n",
        "    # Re-fit the best_model on the entire train_val set\n",
        "    history_final = best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate final model on test\n",
        "    final_test_loss, final_test_acc = best_model.evaluate(X_test, y_test, verbose=1)\n",
        "    print(f\"Test Accuracy (after re-fit on train_val): {final_test_acc:.4f}\")\n",
        "\n",
        "    # Plot training curves for final re-fit\n",
        "    plot_learning_curves(history_final)\n",
        "\n",
        "    # Construct the file paths\n",
        "    model_path = os.path.join(file_path, f\"{model_prefix}_model\")\n",
        "    tokenizer_path = os.path.join(file_path, f\"{model_prefix}_tokenizer\")\n",
        "    config_path = os.path.join(file_path, f\"{model_prefix}_config.json\")\n",
        "\n",
        "    # Save the model weights\n",
        "    print(\"Saving model to:\", model_path)\n",
        "    best_model.save(model_path)\n",
        "\n",
        "    # Save the model tokenizer\n",
        "    print(\"Saving tokenizer to:\", tokenizer_path)\n",
        "    with open(tokenizer_path, \"wb\") as f:\n",
        "        pickle.dump(tokenizer, f)\n",
        "    \n",
        "    # Save configuration\n",
        "    print(\"Save configuration to:\", config_path)\n",
        "    config_data = {\n",
        "        \"max_len\": max_len,\n",
        "        \"vocab_size\": vocab_size\n",
        "    }\n",
        "\n",
        "    with open(config_path, \"w\") as f:\n",
        "        json.dump(config_data, f)\n",
        "\n",
        "    # Print end message\n",
        "    print(f\"GRU Model, tokenizer and configuration stored under {file_path}. Finished Training!\")\n",
        "\n",
        "if mode == ModelRunMode.CLASSIFY.value:\n",
        "    # Construct the file paths\n",
        "    model_path = os.path.join(file_path, f\"{model_prefix}_model\")\n",
        "    tokenizer_path = os.path.join(file_path, f\"{model_prefix}_tokenizer\")\n",
        "    config_path = os.path.join(file_path, f\"{model_prefix}_config.json\")\n",
        "\n",
        "    # Loading model\n",
        "    print(\"Loading model from:\", model_path)\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Loading tokenizer\n",
        "    print(\"Loading tokenizer from:\", tokenizer_path)\n",
        "    with open(tokenizer_path, \"rb\") as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "\n",
        "    # Loading configuration\n",
        "    print(\"Loading configuration from:\", config_path)\n",
        "    with open(config_path, \"r\") as f:\n",
        "         config_data = json.load(f)\n",
        "\n",
        "    # Retrieve the saved configuration max_len\n",
        "    max_len = config_data[\"max_len\"]\n",
        "\n",
        "    # Reading input for classification\n",
        "    df_new = pd.read_csv(input_csv, sep=separator_char)\n",
        "    if \"ID\" not in df_new.columns or \"Text\" not in df_new.columns:\n",
        "        raise ValueError(\"Input CSV must have 'ID' and 'Text' columns for classification.\")\n",
        "\n",
        "    # Clean text\n",
        "    df_new[\"Text\"] = df_new[\"Text\"].apply(text_cleaning)\n",
        "    texts = df_new[\"Text\"].tolist()\n",
        "\n",
        "    # Convert to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Pad\n",
        "    X_new = preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_new)\n",
        "    pred_bin = (preds >= 0.5).astype(int).flatten()\n",
        "    pred_label = np.where(pred_bin == 1, \"AI\", \"Human\")\n",
        "\n",
        "    # Save result\n",
        "    df_out = pd.DataFrame({\"ID\": df_new[\"ID\"], \"Label\": pred_label})\n",
        "    df_out.to_csv(output_csv, sep=separator_char, index=False)\n",
        "    print(f\"Predictions saved to {output_csv}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
